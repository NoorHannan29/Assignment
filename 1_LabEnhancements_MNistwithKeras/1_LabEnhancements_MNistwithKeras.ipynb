{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9_YAf10KYtU"
      },
      "source": [
        "# Machine Learning Lab Enhancement\n",
        "## Lab01 - Keras with MNIST\n",
        "### Lab enhancement made by: **Wan Muhammad Atif bin Taram Satiraksa (1211103154)**\n",
        "### Objectives:\n",
        "1. Explain what is Neural Networks using easy to understand real world examples.\n",
        "2. Demonstrate how to build simple Neural Networks using Keras and the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhw-AzjhLjIE"
      },
      "source": [
        "# **Neural Networks**\n",
        "A Neural Network is a computational model that was inspired by biological neural networks and its way of processing information in the human brain. It is a subset of Machine Learning and Articial Intelligence, primarily used for tasks such as image recognition, speech recognition, and decision-making.\n",
        "\n",
        "Key components of a Neural Network include:\n",
        "1. **Nodes or Neurons**\n",
        "  * The basic unit of a neural network, a node is the equivalent of a neuron in the brain.\n",
        "  * Each node receives input, processes them, and passes the result to the next layer of neurons.\n",
        "  * A node may also consists of:\n",
        "    1. Weights\n",
        "      - Determine the importance of each input in making predictions, adjusted during training to improve accuracy.\n",
        "    2. Bias\n",
        "      - A value added to the weighted sum of inputs to help the network adjust its output and better fit the data by shifting the activation function.\n",
        "    3. Activation function\n",
        "      - Decides where a neuron's output should proceed to the next layer, enabling the network to learn complex, non-linear patterns.\n",
        "\n",
        "2. **Layers**\n",
        "  *   A neural network consist of layers, where each layer houses a varying number of nodes.\n",
        "  * There are 3 types of layers:\n",
        "    1. **Input layer**\n",
        "    \n",
        "        * The first layer that **receives inputs**.\n",
        "        * This layer does not process any information but passes the values of its nodes to the next layer.\n",
        "\n",
        "    2. **Hidden Layers**\n",
        "        * Layers between the input and the output layers where the majority of the processing occurs.\n",
        "        * The number of hidden layers differs for each neural network and neural networks with multiple hidden layers are called **Deep Neural Network (DNN).**\n",
        "\n",
        "    3. **Output Layer**\n",
        "        * The final layer that **receives and provide the output** through suitable methods.\n",
        "\n",
        "\n",
        "3. **Connections**\n",
        "  * Nodes in one layer are inherently connected to neurons in the next layer via edges or weights (does not apply for Output Layer).\n",
        "  * Each connection has a weight that controls the strength of the signal between neurons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLaZYKvlS1fY"
      },
      "source": [
        "# **What is Keras?**\n",
        "Keras is an open source software library that provides easy to use interface for building and training neural networks. It is written in Python, acting as a high level API for creating and experimenting with deep learning models. It is a beginner friendly software, perfect for first time learners in Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdTXL9z8W7oA"
      },
      "source": [
        "# **Example through Analogy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndH4DXwd_XmC"
      },
      "source": [
        "We can use Keras with MNIST to demonstrate how neural networks work with a real life analogy.\n",
        "Let's assume you're an experienced baker trying to make a cake (prediction) from his forgotten childhood memory based on grandma's recipe (data inputs) that **did not specify the name of the cake nor the proportions of its ingredients.**\n",
        "\n",
        "## 1. Input Layer\n",
        "* The ingredients such as **flour, eggs, and sugar** represent the input data which are the** pixel value of the image of the number**.\n",
        "\n",
        "## 2. Weights\n",
        "* Initially, you randomly guess how much of each ingredient is needed. Maybe the first try, you try a mix of 2 cups of flour, 1 cup of sugar and 4 eggs.\n",
        "* During training of the model, these proportions, called weights are adjusted based on your memory of the taste of the cake (minimizing error).\n",
        "\n",
        "## 3. Bias\n",
        "* The oven temperature or baking time can affect the outcome regardless of the ingredients.\n",
        "* For example, even if combination of adjusted ingredients (weight) are perfect, setting the oven temperature (bias) higher or lower can completely change the cake's final look.\n",
        "* In this, bias helps shift the weighted combination of inputs, allowing the model to fit the data more accurately.\n",
        "\n",
        "## 4. Activation Function\n",
        "* After baking, you check the cake via poking it with a chopstick in the middle to test if its properly cooked or if it needs more adjustment.\n",
        "* Activation function works as a test to see whether the output can be passed on or not.\n",
        "\n",
        "##5. Output Layer\n",
        "* Once the cake is ready and its taste evaluated, the baker can identify what type of cake it is (Vanilla, Chocolate, etc).\n",
        "* This is reflected in the neural network as it classifying the input (image) into one of several possible categories (digits 0-9 for MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXhmjsJtU3B3"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MsRKjxyzUtf0"
      },
      "outputs": [],
      "source": [
        "from keras import models, layers\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmC5uRLEU8H8"
      },
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "In this step we load the MNIST dataset (the possible cake names)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ksSBoifVVDP6"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZEISIn-VC6N"
      },
      "source": [
        "# Step 2: Normalize the pixel values to the range [0, 1]\n",
        "We ensure that all pixel values (ingredients) are normalized between 0 to 1 for easier processing. This is similar to adjusting the ingredients to it's appropriate measuring metric (cups, teaspoons, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "32sdvX4_VrTc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ip_pdmV0uI"
      },
      "source": [
        "# Step 3: Build the neural network model\n",
        "The model will contain an Input and Output layer as well as a variable amount of Hidden Layers that is up to your decision. In this model, there are 128 nodes in the hidden layer an it's activation function is ReLU activation. The output layer contains 10 nodes to represent the digits 0-9.\n",
        "\n",
        "## Flatten? Dense? Dropout??\n",
        "There are called Keras layers command which are used to define the architecture of a neural network.\n",
        "\n",
        "In this example, 3 of the commands are used:\n",
        "1. Flatten\n",
        "  - Flatten converts 2D input data (in this case, an image with a 28x28 pixel) into a 1D vector.\n",
        "2. Dense\n",
        "  - Dense creates a fully connected layer where each node is connected to every node in the previous layer using the 1D vector outputted by Flatten.\n",
        "3. Dropout\n",
        "  - Dropout is used to prevent overfitting by randomly setting to zero a certain percentage of the nodes. 20% of the nodes are dropped in this example.\n",
        "  - This forces the model to not overly rely on any single node and helps generalize better to new data.\n",
        "\n",
        "There are many other Keras Layers command which can be found at the [Keras 3 API Documentation](https://keras.io/api/layers/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BUqNlZjpV0AE"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),  # Flatten 28x28 images into 1D vectors\n",
        "    layers.Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n",
        "    layers.Dropout(0.2),                   # Dropout layer for regularization (20% dropout rate)\n",
        "    layers.Dense(10, activation='softmax') # Output layer with 10 neurons (one for each digit 0-9)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAKuMeuPiG69"
      },
      "source": [
        "## What about activation?\n",
        "That is the activation function. As mentioned before, it is a mathematical operation applied to the output of a node in a neural network to introduce non-linearity into the model that helps the neural networks to learn complex patterns in data.\n",
        "\n",
        "Examples of common activation functions:\n",
        "1. ReLU **(used in this example)**\n",
        "2. Softmax\n",
        "3. Sigmoid\n",
        "4. Tanh\n",
        "\n",
        "More activation functions and its description can be found at [Keras 3 API Documentation](https://keras.io/api/layers/activations/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deScfwMoWP4X"
      },
      "source": [
        "# Step 4: Compile the model\n",
        "This is where you finalize how to train your neural network. Pick an optimizer and a loss function to improve how well the cake turns out based on the recipe.\n",
        "\n",
        "## Optimizers, loss function, metrics?\n",
        "  1. Optimizers\n",
        "    - Method used to adjust the model's weights to minimize the loss function\n",
        "    - It is critical in training deep learning models as they help improve the model's ability to make predictions over time.\n",
        "    - Example of Optimizers\n",
        "      * [Adam](https://keras.io/api/optimizers/adam/) **(used in this example)**\n",
        "      * [SGD](https://keras.io/api/optimizers/sgd/)\n",
        "      * [RMSprop](https://keras.io/api/optimizers/rmsprop/)\n",
        "      * [Adagrad](https://keras.io/api/optimizers/adagrad/)\n",
        "  2. Loss function\n",
        "    - Measures how far the model's prediction are from the actual results.\n",
        "    - During model training, the objective is to minimze the loss function to improve the model's accuracy\n",
        "    - Example of Loss Function\n",
        "      * [Sparse Categorical Cross-Entropy](https://) **(used in this example)**\n",
        "      * [Categorical Cross-Entropy](https://)\n",
        "      * [Mean Squared Error](https://) (MSE)\n",
        "      * [Binary Cross-Entropy](https://)\n",
        "      \n",
        "  3. Metrics\n",
        "    - Used to monitor the performance of the model during training and testing.\n",
        "    - Provides a way to track how the model is performing on the task at hand.\n",
        "    - Examples of Metrics\n",
        "      * [Accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class) **(used in this code)**\n",
        "      * [Precision](https://keras.io/api/metrics/classification_metrics/#precision-class)\n",
        "      * [Recall](https://keras.io/api/metrics/classification_metrics/#recall-class)\n",
        "      * [AUC (Area Under the Curve)](https://keras.io/api/metrics/classification_metrics/#auc-class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J82RiyV0WUgo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer= Adam(learning_rate = 0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fKkMxhgWXMl"
      },
      "source": [
        "# Step 5: Train the model\n",
        "Now you start baking the cake (training the model). You follow the recipe and adjust the ingredients as needed in each step based on feedback from the previous attempts (training epochs). Each attempts helps you estimate the correct cake (predicting the correct digit). The accuracy of your estimates increases with more attempts done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Tum0noWaJf",
        "outputId": "ca507542-efcd-4dfd-b2ea-a17501404b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.4838\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1446\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1082\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0859\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0694\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ac66b426110>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oUUjG-MWdav"
      },
      "source": [
        "# Step 6: Evaluate the model on the test data\n",
        "After baking the cake, you do a final taste test (evaluation) which helps in determining how well your cake turned out by comparing it to what you expected (the actual labels in the test data). By testing the model on a test data it has never seen before, you're testing if the model holds true even when used outside its training environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo2dS_iUWhLR",
        "outputId": "b6a6eca0-2593-4efd-a6e9-14ac8cb6c3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.0873\n",
            "Test accuracy: 0.9765999913215637\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrT7UT0IWjV3"
      },
      "source": [
        "# Step 7: Make predictions on the test set\n",
        "The chef now predicts what type of cake it is on the assumption that the cake isn't a new unique cake. This is reflected here be randomly choosing an image from the test set and testing it against the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhHSACYPWnN_",
        "outputId": "49c249cc-54ed-4d88-b3aa-ddc3af9453a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n"
          ]
        }
      ],
      "source": [
        "random_index = np.random.randint(0, len(X_test))\n",
        "predicted_label = model.predict(X_test[random_index:random_index+1])\n",
        "predicted_digit = predicted_label.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH-fsZNrWo9V"
      },
      "source": [
        "# Step 8: Display a sample prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "vPHpEmBVWolM",
        "outputId": "64139a7e-a4af-4c2d-b118-ec372e985662"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_test[random_index], cmap=plt.cm.binary)\n",
        "plt.title(f\"Predicted Digit: {predicted_digit}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etbyF-n6SVqb"
      },
      "source": [
        "# Additional Exercises (Future Work)\n",
        "To further enhance understanding, consider the following exercises:\n",
        "\n",
        "1. Experiment with Different Architectures:\n",
        "\n",
        "    * Modify the number of hidden layers and neurons.\n",
        "\n",
        "    * Observe the impact on accuracy and training time.\n",
        "\n",
        "2. Try Different Activation Functions:\n",
        "\n",
        "    * Replace ReLU with Sigmoid or Tanh in the hidden layers.\n",
        "\n",
        "    * Compare performance differences in accuracy.\n",
        "\n",
        "3. Optimize Hyperparameters:\n",
        "\n",
        "    * Experiment with different optimizers (SGD, RMSprop, Adamax).\n",
        "\n",
        "    * Tune **learning rates** (eg., 0.01, 0.001, 0.0001), **batch sizes** (e.g., 32,64,128), and **dropout rates** (e.g., 0.2, 0.5) and find the optimal setting.\n",
        "4. Train on a Custom Dataset:\n",
        "\n",
        "    * Replace MNIST with Fashion-MNIST by replacing mnist.load_data() with fashion_mnist.load_data().\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
